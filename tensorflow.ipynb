{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETUP THE VARIABLES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "instance_type = \"local\"\n",
    "\n",
    "if subprocess.call(\"nvidial-smi\") == 0 :\n",
    "    local_hyperparameters = {\"epochs\": 1 , \"batch-size\" : 64}\n",
    "\n",
    "    estimator = TensorFlow (\n",
    "        entry_point = \"cifar10_keras_main.py\" ,\n",
    "        source_dir = \"source_dir\" ,\n",
    "        role = role ,\n",
    "        framework_version = \"1.15.2\"\n",
    "        py_version = \"py3\" ,\n",
    "        hyperparameters = local_hyperparameters ,\n",
    "        train_instance_count =1 ,\n",
    "        train_instance_type = instance_type ,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "data_path = os.path.join(os.getcwd(),\"data\")\n",
    "\n",
    "local_inputs = {\n",
    "    \"train\":\"file://{}/train\".format(data_path),\n",
    "    \"validation\":\"file://{}/validation\".format(data_path),\n",
    "    \"eval\":\"file://{}/eval\".format(data_path),\n",
    "}\n",
    "\n",
    "estimator.fit(local_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_definitions = [\n",
    "        {\"Name\": \"train:loss\", \"Regex\": \".*loss: ([0-9\\\\.]+) - accuracy: [0-9\\\\.]+.*\"},\n",
    "    {\"Name\": \"train:accuracy\", \"Regex\": \".*loss: [0-9\\\\.]+ - accuracy: ([0-9\\\\.]+).*\"},\n",
    "    {\n",
    "        \"Name\": \"validation:accuracy\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: ([0-9\\\\.]+).*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"validation:loss\",\n",
    "        \"Regex\": \".*step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: ([0-9\\\\.]+) - val_accuracy: [0-9\\\\.]+.*\",\n",
    "    },\n",
    "    {\n",
    "        \"Name\": \"sec/steps\",\n",
    "        \"Regex\": \".* - \\d+s (\\d+)[mu]s/step - loss: [0-9\\\\.]+ - accuracy: [0-9\\\\.]+ - val_loss: [0-9\\\\.]+ - val_accuracy: [0-9\\\\.]+\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import Tensorflow\n",
    "\n",
    "hyperparameters = {\"epochs\":10 , \"batch_size\":256}\n",
    "tags = [{\"key\": \"Project\" , \"value\" : \"cifar10\"}, {\"key\" ,\"TensorBoard\" , \"Value\" : \"file\"}]\n",
    "\n",
    "estimator = Tensorflow (\n",
    "    entry_point = \"cifar10_keras_main.py\" ,\n",
    "    source_dir = \"source_dir\" ,\n",
    "    metric_definitions = metric_definitions ,\n",
    "    hyperparameters = hyperparameters ,\n",
    "    role = role ,\n",
    "    framework_version = framework_version ,\n",
    "    py_version = \"py3\" ,\n",
    "    train_instance_count = 1 ,\n",
    "    train_instance_type =\"ml.p2.xlarge\"\n",
    "    base_job_name = \"cifar10-tf\" ,\n",
    "    tags = tags \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"train\": \"{}/train\".format(dataset_uri) ,\n",
    "    \"validation\": \"{}/validation\".format(dataset_uri),\n",
    "     \"eval\" : \"{}/eval\".format(dataset_uri),\n",
    "}\n",
    "\n",
    "estimator.fit(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib import parse\n",
    "\n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "cw_url = parse.urlunparse(\n",
    "    (\n",
    "        \"https\",\n",
    "        \"{}.console.aws.amazon.com\".format(region),\n",
    "        \"/cloudwatch/home\",\n",
    "        \"\",\n",
    "        \"region={}\".format(region),\n",
    "        \"metricsV2:namespace=/aws/sagemaker/TrainingJobs;dimensions=TrainingJobName;search={}\".format(\n",
    "            estimator.latest_training_job.name\n",
    "        ),\n",
    "    )\n",
    ")\n",
    "\n",
    "display(\n",
    "    Markdown(\n",
    "        \"CloudWatch metrics: [link]({}). After you choose a metric, \"\n",
    "        \"change the period to 1 Minute (Graphed Metrics -> Period).\".format(cw_url)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mode_estimator = Tensorflow (\n",
    "    entry_point = \"cifar10_keras_main.py\" ,\n",
    "    source_dir = \"source_dir\" , \n",
    "    metric_definitions = metric_definitions ,\n",
    "    hyperparameters = hyperparameters ,\n",
    "    role = role ,\n",
    "    framework_version = \"1.15.2\" ,\n",
    "    py_version = \"py3\" ,\n",
    "    train_instance_count = \"m1.p2.xlarge\" , \n",
    "    input_mode = \"Pipe\" ,\n",
    "    base_job_name = \"cifar10-tf-pipe\" ,\n",
    "    tags = tags ,\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_mode_estimator.fit(inputs ,wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = {\n",
    "    \"mpi\": {\n",
    "        \"enabled\" : True ,\n",
    "        \"processes_per_host\": 1,\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_estimator = TensorFlow (\n",
    "      entry_point=\"cifar10_keras_main.py\",\n",
    "    source_dir=\"source_dir\",\n",
    "    metric_definitions=metric_definitions,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distributions=distribution,\n",
    "    role=role,\n",
    "    framework_version=\"1.15.2\",\n",
    "    py_version=\"py3\",\n",
    "    train_instance_count=2,\n",
    "    train_instance_type=\"ml.p3.2xlarge\",\n",
    "    base_job_name=\"cifar10-tf-dist\",\n",
    "    tags=tags,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_estimator.fit(inputs , wait = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python generate_tensorboard_command.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1 , instance_type = \"ml.m4.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.randn(1,32,32,3)\n",
    "\n",
    "print(\"Predicted class : {}\".format(np.argmax(predict.predict(data[\"predictions\"]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  keras.datasets import cifar10\n",
    "\n",
    "(x_train , y_train) , (x_test,y_train) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def predict(data):\n",
    "    predictions = predictor.predict(data)[\"predictions\"]\n",
    "    return predictions\n",
    "\n",
    "predicted = []\n",
    "actual = []\n",
    "batches = 0 \n",
    "batch_size = 128\n",
    "\n",
    "datagen = ImageDataGenerator()\n",
    "for data in datagen.flow(x_test,y_test, batch_size=batch_size)\n",
    "for i , prediction in enumarate(predict(data[0])):\n",
    "    predicted.append(np.argmax(prediction))\n",
    "    actual.append(data[1][i][0])\n",
    "\n",
    "    batches += 1\n",
    "    if batches >= len(x_test) /batch_size:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_pred=predicted, y_true=actual)\n",
    "cm = cm.astype(\"float\") / cm.sum(axis=1)[:, np.newaxis]\n",
    "sn.set(rc={\"figure.figsize\": (11.7, 8.27)})\n",
    "sn.set(font_scale=1.4)  # for label size\n",
    "sn.heatmap(cm, annot=True, annot_kws={\"size\": 10})  # font size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
